{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Histopathologic cancer detection plays a critical role in the early diagnosis and treatment of cancer, significantly impacting patient outcomes. One of the most promising avenues for enhancing the accuracy and efficiency of cancer detection is through the application of deep learning techniques. In this context, Kaggle hosts an exciting competition aimed at harnessing the power of artificial intelligence to identify metastatic cancer in small image patches extracted from larger digital pathology scans.\n",
    "\n",
    "The competition revolves around a dataset derived from the PatchCamelyon (PCam) benchmark dataset, with slight modifications to remove duplicate images. PCam, renowned for its substantial size, accessibility, and ease of use, presents an ideal platform for both seasoned machine learning practitioners and those looking to embark on their deep learning journey. As the competition description aptly notes, PCam offers a unique opportunity to make a tangible impact on histopathologic cancer detection through data-driven solutions.\n",
    "\n",
    "The Kaggle link to the challenge can be found here: https://www.kaggle.com/c/histopathologic-cancer-detection/overview\n",
    "\n",
    "The dataset contains:\n",
    "\n",
    "    1. test images with file name as the ID.\n",
    "    2. train images with file name as the ID.\n",
    "    3. train_labels.csv with two features.\n",
    "        - ID linking train image to row.\n",
    "        - Label binary classification acknowledging presence of cancer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run this locally it is recommended to first run \"create_venv.sh\". This will create a python3 virtual environment when running in Linux. Other steps will need to be taken if using MacOSx or Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_labels.csv data is quite clean and contains an image id along with the label. No null counts were found and no cleaning is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n----- Null counts -----\")\n",
    "null_counts = df.isna().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of tumor or no tumor is inbalanced. Yet, there is so much data available ~210000 images this will have little impact on this lab as for time's sake we will take a subset of these images for the model to save on training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = zip(*Counter(df[\"label\"]).items())\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, counts, color=[\"green\", \"red\"])\n",
    "plt.xlabel(\"Label (0 = No Tumor, 1 = Tumor)\")\n",
    "plt.ylabel(\"Image Count\")\n",
    "plt.title(\"Distribution of Labels in the Data\")\n",
    "plt.xticks(labels)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at some of the images with either of the two labels. There is no noteable difference between the two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_to_display = 3\n",
    "\n",
    "df[\"path\"] = df[\"id\"].apply(lambda x: os.path.join(\"train\", str(x) + \".tif\"))\n",
    "images_with_label_0 = df[df[\"label\"] == 0]\n",
    "images_with_label_1 = df[df[\"label\"] == 1]\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    image = plt.imread(images_with_label_0[\"path\"].iloc[i])\n",
    "\n",
    "    plt.subplot(2, num_images_to_display, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Label 0\")\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    image = plt.imread(images_with_label_1[\"path\"].iloc[i])\n",
    "\n",
    "    plt.subplot(2, num_images_to_display, num_images_to_display + i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Label 1\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem as if all these images are of the same width, height and channel count. But check these are all the same is worth while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dimensions = set()\n",
    "random_indices = np.random.randint(0, len(df), 1000)\n",
    "for index in random_indices:\n",
    "    image = io.imread(df[\"path\"].iloc[index])\n",
    "    image_height, image_width, image_channels = image.shape\n",
    "    unique_dimensions.add((image_height, image_width, image_channels))\n",
    "\n",
    "print(f\"Unique dimension: {unique_dimensions}\")\n",
    "print(f\"Image Height: {image_height} pixels\")\n",
    "print(f\"Image Width: {image_width} pixels\")\n",
    "print(f\"Number of Channels (Depth): {image_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure we gain the benefit of exploring different model changes we can take a subset of all our samples by taking 10000 images with label 0 and 10000 images with label 1. We can then use this as our training data and split it into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].astype(str)\n",
    "df_0 = df[df[\"label\"] == \"0\"].sample(10000, random_state=42)\n",
    "df_1 = df[df[\"label\"] == \"1\"].sample(10000, random_state=42)\n",
    "df_subset = pd.concat([df_0, df_1], ignore_index=True)\n",
    "\n",
    "train_file_paths, test_file_paths, train_labels, test_labels = train_test_split(df_subset[\"path\"], df_subset[\"label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class ImageDataGenerator is a Keras library used with data augmentation and preprocessing of image data with deep learning tasks. We gain the following benefits:\n",
    "- Augmenting the training data with rotations, width and height shifts, shearing, zooming and flipping reduces the changes we overfit our data. \n",
    "- Pixel scaling is done to normalize the pixel data giving a boost to the covergence of the training process. \n",
    "- Efficient loading allows us to work directly directories of images or dataframe.\n",
    "\n",
    "We will use the directory load method but will need to split our chosen subset of data into a train folder and test folder. So we will copy these images to these new folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory called train_data and copy the training data into it\n",
    "train_dir = \"train_data\"\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(os.path.join(train_dir, \"0\"))\n",
    "os.makedirs(os.path.join(train_dir, \"1\"))\n",
    "for file_path, label in zip(train_file_paths, train_labels):\n",
    "    name = file_path.split(\"/\")[-1]\n",
    "    if label == \"0\":\n",
    "        shutil.copy2(file_path, os.path.join(train_dir, \"0\", name))\n",
    "    else:\n",
    "        shutil.copy2(file_path, os.path.join(train_dir, \"1\", name))\n",
    "\n",
    "# Create directory called test_data and copy the test data into it\n",
    "test_dir = \"test_data\"\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "os.makedirs(test_dir)\n",
    "os.makedirs(os.path.join(test_dir, \"0\"))\n",
    "os.makedirs(os.path.join(test_dir, \"1\"))\n",
    "for file_path, label in zip(test_file_paths, test_labels):\n",
    "    name = file_path.split(\"/\")[-1]\n",
    "    if label == \"0\":\n",
    "        shutil.copy2(file_path, os.path.join(test_dir, \"0\", name))\n",
    "    else:\n",
    "        shutil.copy2(file_path, os.path.join(test_dir, \"1\", name))\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DModel Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have image data with an image height and width of 96 and 3 image channels (RGB). We wish to perform binary classification on the data. Some of the reasoning for the model below are as stated.\n",
    "\n",
    "- Sigmoid Activation in Output Layer: The model uses a sigmoid activation function in the output layer, which is suitable for binary classification. Sigmoid squashes the output to the range [0, 1], making it interpretable as a probability. We can threshold the output at 0.5 to make binary predictions.\n",
    "\n",
    "- Binary Cross-Entropy Loss: It's common to use binary cross-entropy loss with sigmoid activation for binary classification tasks. Binary cross-entropy measures the dissimilarity between the predicted probabilities and the actual binary labels.\n",
    "\n",
    "- Convolutional Layers: Convolutional layers are effective at learning hierarchical features from images. They can capture low-level features like edges and high-level features like shapes, which are important for distinguishing objects or patterns in binary classification.\n",
    "\n",
    "- Max-Pooling Layers: Max-pooling layers help reduce the spatial dimensions of the feature maps while retaining the most important information. This down-sampling can help the model focus on the most discriminative features.\n",
    "\n",
    "- Batch Normalization: Batch normalization helps in stabilizing and accelerating the training process. It normalizes the activations of the previous layer, which can prevent issues like vanishing gradients and improve convergence.\n",
    "\n",
    "- Dropout: The dropout layer with a rate of 0.5 is included to prevent overfitting. During training, dropout randomly deactivates a fraction of neurons, forcing the model to learn more robust features.\n",
    "\n",
    "- Flatten Layer: After the convolutional layers, the Flatten layer is used to convert the 2D feature maps into a 1D vector, which is necessary for connecting to the dense layers for classification.\n",
    "\n",
    "- Dense Layers: The model includes fully connected dense layers, which can capture complex relationships in the data. The first dense layer with 64 units provides the model with expressive power, and the final dense layer with a single neuron outputs the binary classification result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are handful hyperparameters that could be modified in this model.\n",
    "\n",
    "- Learning Rate: Learning rate controls the step size during optimization. Higher learning rates can lead to faster convergence but may risk overshooting the optimal solution. Lower learning rates may be more stable but require longer training.\n",
    "\n",
    "- Optimizer: The optimizer algorithm affects how the model's weights are updated during training. Adam is a popular choice and often works well in practice. RMSprop and SGD (Stochastic Gradient Descent) are also viable options. Each optimizer has its own set of hyperparameters (e.g., momentum for SGD) that we can tune.\n",
    "\n",
    "- Number of Epochs: The number of training epochs determines how many times the model sees the entire training dataset. Too few epochs may result in underfitting, while too many may lead to overfitting.\n",
    "\n",
    "- Batch Size: The batch size defines how many samples are processed in each forward and backward pass. Smaller batch sizes may lead to slower training but can help generalize better. Larger batch sizes may speed up training but could result in overfitting.\n",
    "\n",
    "- Dropout Rate: Dropout is a regularization technique that helps prevent overfitting. The dropout rate determines the probability of dropping out a neuron during training. We can use values between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model we'll use the following hyperparameters:\n",
    "\n",
    "- Learning Rate = 0.001\n",
    "- Optimizer = RMSprop\n",
    "- Epoch Number = 10\n",
    "- Batch Size = 32\n",
    "- Dropout Rate = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "optimizer = RMSprop(learning_rate=learning_rate)\n",
    "training_epochs = 10\n",
    "batch_size = 32\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model1 = Sequential()\n",
    "pool_size = (3, 3)\n",
    "filter_size = (3, 3)\n",
    "\n",
    "# Convolutional layers\n",
    "model1.add(Conv2D(16, filter_size, activation='relu', input_shape=(image_width, image_height, image_channels)))\n",
    "model1.add(Conv2D(16, filter_size, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(pool_size=pool_size))\n",
    "\n",
    "model1.add(Conv2D(32, filter_size, activation='relu'))\n",
    "model1.add(Conv2D(32, filter_size, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(pool_size=pool_size))\n",
    "\n",
    "model1.add(Conv2D(64, filter_size, activation='relu'))\n",
    "model1.add(Conv2D(64, filter_size, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(pool_size=pool_size))\n",
    "\n",
    "# Convert to 1D vector\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Classification layers\n",
    "model1.add(Dense(64, activation='sigmoid'))\n",
    "model1.add(Dropout(dropout_rate))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "train_steps_per_epoch=train_generator.n//train_generator.batch_size\n",
    "validation_steps_per_epoch=test_generator.n//test_generator.batch_size\n",
    "history1 = model1.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=training_epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=validation_steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second model we'll use the following hyperparameters:\n",
    "\n",
    "- Learning Rate = 0.01\n",
    "- Optimizer = SGD\n",
    "- Epoch Number = 10\n",
    "- Batch Size = 32\n",
    "- Dropout Rate = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "optimizer = SGD(learning_rate=learning_rate)\n",
    "training_epochs = 10\n",
    "batch_size = 32\n",
    "dropout_rate = 0.25\n",
    "\n",
    "model2 = Sequential()\n",
    "pool_size = (3, 3)\n",
    "filter_size = (3, 3)\n",
    "\n",
    "# Convolutional layers\n",
    "model2.add(Conv2D(16, filter_size, activation='relu', input_shape=(image_width, image_height, image_channels)))\n",
    "model2.add(Conv2D(16, filter_size, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPool2D(pool_size=pool_size))\n",
    "\n",
    "model2.add(Conv2D(32, filter_size, activation='relu'))\n",
    "model2.add(Conv2D(32, filter_size, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPool2D(pool_size=pool_size))\n",
    "\n",
    "model2.add(Conv2D(64, filter_size, activation='relu'))\n",
    "model2.add(Conv2D(64, filter_size, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPool2D(pool_size=pool_size))\n",
    "\n",
    "# Convert to 1D vector\n",
    "model2.add(Flatten())\n",
    "\n",
    "# Classification layers\n",
    "model2.add(Dense(64, activation='sigmoid'))\n",
    "model2.add(Dropout(dropout_rate))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "train_steps_per_epoch=train_generator.n//train_generator.batch_size\n",
    "validation_steps_per_epoch=test_generator.n//test_generator.batch_size\n",
    "history2 = model2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=training_epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=validation_steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model one showed a notable difference in the loss function as the number of epochs increased. After about 8 epochs the validation loss appeared to be lowering to a new minimum which suggests more epochs could have found the next minimum. The learning rate could have been responsible for the slower convergence. Where as Model two appeared move to near minimum and maximum values quite quickly and showed no signs or converging around an optimal solution. \n",
    "\n",
    "Should be noted that the optimal solution was not clear based on the limited number of epochs done. There was no point in either model where the training loss continued to decreased and the validation loss continually increased. This would indicate an inflexion point between underfitting and overfitting the training data. There was a limitation in this module to computing resources that limited further exploration in that regards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the training history from the 'history' object of each model\n",
    "training_loss1 = model1.history.history['loss']\n",
    "validation_loss1 = model1.history.history['val_loss']\n",
    "training_loss2 = model2.history.history['loss']\n",
    "validation_loss2 = model2.history.history['val_loss']\n",
    "epochs = range(1, len(training_loss1) + 1)\n",
    "\n",
    "# Create a subplot for training loss for Model 1\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, training_loss1, label='Training Loss (Model 1)', color='blue')\n",
    "plt.plot(epochs, validation_loss1, label='Validation Loss (Model 1)', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss for Model 1')\n",
    "plt.grid(True)\n",
    "\n",
    "# Create a subplot for training loss for Model 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, training_loss2, label='Training Loss (Model 2)', color='blue')\n",
    "plt.plot(epochs, validation_loss2, label='Validation Loss (Model 2)', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss for Model 2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the training history from the 'history' object of each model\n",
    "training_acc1 = model1.history.history['accuracy']\n",
    "validation_acc1 = model1.history.history['val_accuracy']\n",
    "training_acc2 = model2.history.history['accuracy']\n",
    "validation_acc2 = model2.history.history['val_accuracy']\n",
    "\n",
    "# Create an array of epochs for the x-axis\n",
    "epochs = range(1, len(training_acc1) + 1)\n",
    "\n",
    "# Create a subplot for training accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, training_acc1, label='Training Accuracy (Model 1)', color='blue')\n",
    "plt.plot(epochs, validation_acc1, label='Validation Accuracy (Model 1)', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy for Model 1')\n",
    "plt.grid(True)\n",
    "\n",
    "# Create a subplot for validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, training_acc2, label='Training Accuracy (Model 2)', color='blue')\n",
    "plt.plot(epochs, validation_acc2, label='Validation Accuracy (Model 2)', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy for Model 2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(columns=[\"id\", \"label\"])\n",
    "\n",
    "test_file_paths = []\n",
    "for root, _, files in os.walk(\"test\"):\n",
    "    for name in files:\n",
    "        test_file_paths.append(os.path.join(root, name))\n",
    "\n",
    "for file in test_file_paths:\n",
    "    image = io.imread(file)\n",
    "    id = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    prediction = model1.predict(image.reshape(1, 96, 96, 3), verbose=0)\n",
    "\n",
    "    # Use len(submission_df) to determine the index\n",
    "    row = {\"id\": id, \"label\": 0 if prediction < 0.5 else 1}\n",
    "    submission_df.loc[len(submission_df)] = row\n",
    "    print(f\"Progress: {len(submission_df)}/{len(test_file_paths)}\", end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, our analysis of two distinct models has revealed valuable insights into their training behaviors. Model 1 demonstrated a promising capacity for learning, with notable reductions in the loss function as epochs progressed. The validation loss suggested potential for further improvement, although careful consideration of the learning rate's impact on convergence is warranted.\n",
    "\n",
    "On the other hand, Model 2 exhibited rapid convergence to both low and high loss values, highlighting potential instability in training. This behavior prompts a closer examination of hyperparameters, model architecture, and data quality as possible contributing factors.\n",
    "\n",
    "Despite these observations, limitations in computing resources constrained our ability to explore these models comprehensively. Nevertheless, we recommend further experimentation, including hyperparameter tuning, monitoring loss curves over extended training periods, and potential adoption of more advanced model architectures or ensemble techniques. Additionally, maintaining data quality and preprocessing vigilance is crucial in pursuit of improved model performance.\n",
    "\n",
    "In conclusion, the journey of training deep learning models is an iterative process that demands diligent experimentation and refinement to unlock their full potential for solving specific problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
